# Data-Processing-Pipeline

# ğŸ“Š Data Processing Pipeline with Yahoo Finance, PostgreSQL, Docker, and Airflow

## ğŸš€ Project Overview
This project is a **real-time stock data processing pipeline** that retrieves stock prices from the **Yahoo Finance API**, stores them in a **PostgreSQL database**, and automates the workflow using **Apache Airflow DAGs**. The entire system runs within **Docker containers** for easy deployment and scalability.

## ğŸ“Œ Features
- Fetches **real-time stock data** from the **Yahoo Finance API**.
- Stores the data in a **PostgreSQL database**.
- Uses **Apache Airflow DAGs** for scheduling, automation, and logging.
- Runs inside **Docker containers** for seamless deployment.
- Logs all key events for monitoring and debugging.

## ğŸ› ï¸ Tech Stack
- **Yahoo Finance API** (`yfinance` Python library)
- **PostgreSQL** for data storage
- **Apache Airflow** for workflow automation
- **Docker** for containerized deployment
- **Python** for data processing

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ dags/
    â”œâ”€â”€ DAG1.py                  # Apache Airflow DAG for stock-data retriveal and storage automation
â”œâ”€â”€ docker-compose.yml           # Docker Compose configuration
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # Project documentation
â”œâ”€â”€ Dockerfile                  # Docker image configuration (defines environment, dependencies, and setup)
```

## Future Improvements
- **Spark:** Advanced data manipulation.
- **Airbyte/Redis** Real-Time data ingestion.



